{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"        \\\n",
    "\n",
    "import glob, json, random, logging, gc, re\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "import inspect\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f320037",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_ROOT      = \"data/VNEMOS\"\n",
    "PROC_WAV_DIR  = \"wavs16k\"\n",
    "OUTPUT_DIR    = \"output\"\n",
    "\n",
    "LOCAL_MODEL   = \"vinai/PhoWhisper-base\"\n",
    "PUNC_MODEL    = \"vinai/bartpho-word-base\"\n",
    "\n",
    "TEST_RUN      = True     # đặt False khi chạy thật\n",
    "TEST_COUNT    = 5\n",
    "VALID_RATIO   = 0.10\n",
    "TEST_RATIO    = 0.10\n",
    "RANDOM_SEED   = 42\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    ")\n",
    "Path(PROC_WAV_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Loading faster-whisper (PhoWhisper-base, CPU-INT8) …\")\n",
    "t0 = perf_counter()\n",
    "cpu_threads  = max(1, os.cpu_count() // 2)   # chia nửa core để còn luồng hệ thống\n",
    "\n",
    "asr_model = WhisperModel(\n",
    "    \"pho_base_ct2\",        \n",
    "    device=\"cpu\",\n",
    "    compute_type=\"int8\",\n",
    "    cpu_threads=os.cpu_count() // 2,\n",
    ")\n",
    "logging.info(\n",
    "    f\"faster-whisper ready | threads={cpu_threads} | \"\n",
    "    f\"load_time={perf_counter() - t0:.1f}s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5262d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_transcribe_kwargs(model):\n",
    "    sig = inspect.signature(model.transcribe)\n",
    "    params = sig.parameters\n",
    "    kw = dict(beam_size=5, vad_filter=True)\n",
    "\n",
    "    # tên độ dài đoạn\n",
    "    if \"chunk_length\" in params:\n",
    "        kw[\"chunk_length\"] = 20\n",
    "    elif \"chunk_length_s\" in params:\n",
    "        kw[\"chunk_length_s\"] = 20\n",
    "\n",
    "    # tên độ chồng\n",
    "    if \"chunk_overlap\" in params:\n",
    "        kw[\"chunk_overlap\"] = 5\n",
    "    elif \"chunk_overlap_s\" in params:\n",
    "        kw[\"chunk_overlap_s\"] = 5\n",
    "    elif \"stride_length\" in params:\n",
    "        kw[\"stride_length\"] = 5\n",
    "    elif \"stride\" in params:           # bản 1.1.x\n",
    "        kw[\"stride\"] = (5, 5)\n",
    "\n",
    "    return kw\n",
    "\n",
    "TRANS_KWARGS = _build_transcribe_kwargs(asr_model)\n",
    "logging.info(f\"Transcribe kwargs: {TRANS_KWARGS}\")\n",
    "\n",
    "# ──────────────────────── PUNCTUATION (PyTorch) ─────────────────────────────\n",
    "logging.info(\"Loading punctuation model (BARTpho-word) …\")\n",
    "t0 = perf_counter()\n",
    "punc_tok   = AutoTokenizer.from_pretrained(PUNC_MODEL, use_fast=True)\n",
    "punc_model = AutoModelForSeq2SeqLM.from_pretrained(PUNC_MODEL).eval().to(\"cpu\")\n",
    "logging.info(f\"Punctuation ready in {perf_counter()-t0:.1f}s\")\n",
    "\n",
    "@torch.inference_mode()\n",
    "def restore_punctuation(text: str) -> str:\n",
    "    enc = punc_tok(text, return_tensors=\"pt\")\n",
    "    enc.pop(\"token_type_ids\", None)         \n",
    "    out = punc_model.generate(\n",
    "        **enc,\n",
    "        max_length=enc[\"input_ids\"].shape[1] + 16,\n",
    "        do_sample=False,\n",
    "    )\n",
    "    return punc_tok.decode(out[0], skip_special_tokens=True).capitalize()\n",
    "\n",
    "# ───────────────────────────── ASR WRAPPER ──────────────────────────────────\n",
    "def transcribe(path: str) -> str:\n",
    "    segments, _ = asr_model.transcribe(path, **TRANS_KWARGS)\n",
    "    return \" \".join(seg.text.strip() for seg in segments)\n",
    "\n",
    "# ───────────────────────────── LOAD & RESAMPLE ──────────────────────────────\n",
    "logging.info(\"Scanning raw WAV files …\")\n",
    "items = []\n",
    "for wav in glob.glob(os.path.join(RAW_ROOT, \"**\", \"*.wav\"), recursive=True):\n",
    "    rel = Path(wav).relative_to(RAW_ROOT)\n",
    "    emotion, speaker = rel.parts[0].lower(), rel.parts[1]\n",
    "    utt_id = re.sub(r\"\\s+\", \"_\", rel.stem)\n",
    "    items.append({\"wav_original\": wav, \"wav_id\": utt_id,\n",
    "                  \"speaker_id\": speaker, \"emotion\": emotion})\n",
    "\n",
    "if TEST_RUN:\n",
    "    items = items[:TEST_COUNT]\n",
    "    logging.info(f\"TEST_RUN=True → {len(items)} files only\")\n",
    "\n",
    "logging.info(\"Resampling to 16 kHz mono …\")\n",
    "for itm in tqdm(items, desc=\"Resample\"):\n",
    "    y, sr = sf.read(itm[\"wav_original\"], dtype=\"float32\", always_2d=True)\n",
    "    y = y.mean(axis=1)\n",
    "    if sr != 16000:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "    if (p := np.max(np.abs(y)) + 1e-9) > 1.0:\n",
    "        y = y / p\n",
    "    dst = Path(PROC_WAV_DIR)/f\"{itm['wav_id']}.wav\"\n",
    "    sf.write(dst, y, 16000, subtype=\"PCM_16\")\n",
    "    itm.update({\"wav_path\": str(dst), \"duration\": len(y)/16000})\n",
    "\n",
    "# ────────────────────────── STT + PUNCTUATION ───────────────────────────────\n",
    "logging.info(\"Running ASR + punctuation …\")\n",
    "metadata = []\n",
    "for itm in tqdm(items, desc=\"STT\"):\n",
    "    raw  = transcribe(itm[\"wav_path\"])\n",
    "    text = restore_punctuation(raw)\n",
    "    metadata.append({\n",
    "        \"utterance_id\": itm[\"wav_id\"],\n",
    "        \"speaker_id\" : itm[\"speaker_id\"],\n",
    "        \"wav_path\"   : itm[\"wav_path\"],\n",
    "        \"start\"      : 0.0,\n",
    "        \"end\"        : itm[\"duration\"],\n",
    "        \"transcript\" : text,\n",
    "        \"emotion\"    : itm[\"emotion\"],\n",
    "    })\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c0e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Saving JSONL & splitting …\")\n",
    "Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "with open(Path(OUTPUT_DIR)/\"vnemos_all.jsonl\",\"w\",encoding=\"utf-8\") as f:\n",
    "    for row in metadata:\n",
    "        f.write(json.dumps(row, ensure_ascii=False)+\"\\n\")\n",
    "\n",
    "spk = list({m[\"speaker_id\"] for m in metadata}); random.shuffle(spk)\n",
    "val_n = max(1,int(len(spk)*VALID_RATIO)); test_n=max(1,int(len(spk)*TEST_RATIO))\n",
    "val_spk=set(spk[:val_n]); test_spk=set(spk[val_n:val_n+test_n])\n",
    "train_spk=set(spk[val_n+test_n:])\n",
    "\n",
    "for name,grp in {\"train\":train_spk,\"valid\":val_spk,\"test\":test_spk}.items():\n",
    "    out=Path(OUTPUT_DIR)/f\"{name}.jsonl\"; cnt=0\n",
    "    with open(out,\"w\",encoding=\"utf-8\") as f:\n",
    "        for rec in metadata:\n",
    "            if rec[\"speaker_id\"] in grp:\n",
    "                f.write(json.dumps(rec, ensure_ascii=False)+\"\\n\"); cnt+=1\n",
    "    logging.info(f\"{name:5s}: {cnt:4d} utt | {len(grp)} spk\")\n",
    "\n",
    "logging.info(\"Done ✔  All outputs in ./output/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
