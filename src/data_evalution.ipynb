{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5d1a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found splits: ['train', 'valid', 'test']\n",
      "Total rows: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing/Unreadable files: 0\n",
      "Duplicate absolute wav paths (any split): 0\n",
      "Duplicate utterance_id across splits: 0\n",
      "Duplicate JSONL wav_path across splits: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXISTENCE / DUPLICATION / LEAKAGE ===\n",
      "Missing files: 0\n",
      "Duplicate absolute wav paths: 0\n",
      "Duplicate utterance_id across splits: 0\n",
      "Duplicate JSONL wav_path across splits: 0\n",
      "Speaker overlap across splits: {('train', 'valid'): 0, ('train', 'test'): 0, ('valid', 'test'): 0}\n",
      "\n",
      "=== LABEL BALANCE (per split) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "IR_max/min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "H_norm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Gini",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cnt_angry",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cnt_fear",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cnt_happiness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cnt_neutral",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cnt_sadness",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "1d53ce5e-a849-40f2-8939-971bb111cafb",
       "rows": [
        [
         "0",
         "train",
         "1.162162162162162",
         "0.9989895443607331",
         "0.79935",
         "43",
         "38",
         "42",
         "37",
         "40",
         "200"
        ],
        [
         "1",
         "valid",
         "1.5",
         "0.9949956407991567",
         "0.7968",
         "4",
         "5",
         "5",
         "5",
         "6",
         "25"
        ],
        [
         "2",
         "test",
         "2.6666666666666665",
         "0.9463711715521069",
         "0.7647999999999999",
         "3",
         "7",
         "3",
         "8",
         "4",
         "25"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>IR_max/min</th>\n",
       "      <th>H_norm</th>\n",
       "      <th>Gini</th>\n",
       "      <th>cnt_angry</th>\n",
       "      <th>cnt_fear</th>\n",
       "      <th>cnt_happiness</th>\n",
       "      <th>cnt_neutral</th>\n",
       "      <th>cnt_sadness</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>1.162162</td>\n",
       "      <td>0.998990</td>\n",
       "      <td>0.79935</td>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valid</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.994996</td>\n",
       "      <td>0.79680</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.946371</td>\n",
       "      <td>0.76480</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  IR_max/min    H_norm     Gini  cnt_angry  cnt_fear  cnt_happiness  \\\n",
       "0  train    1.162162  0.998990  0.79935         43        38             42   \n",
       "1  valid    1.500000  0.994996  0.79680          4         5              5   \n",
       "2   test    2.666667  0.946371  0.76480          3         7              3   \n",
       "\n",
       "   cnt_neutral  cnt_sadness  total  \n",
       "0           37           40    200  \n",
       "1            5            6     25  \n",
       "2            8            4     25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOKEN LENGTH & TRUNCATION (per split) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tok_p0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tok_p25",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tok_p50",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tok_p75",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tok_p90",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tok_p95",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tok_p99",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tok_p100",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tok_over_maxlen",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tok_over_rate",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a218a120-0d0d-4a8c-9300-4578fe53c239",
       "rows": [
        [
         "0",
         "train",
         "5.0",
         "14.75",
         "22.0",
         "33.0",
         "44.0",
         "48.0",
         "60.069999999999936",
         "72.0",
         "2",
         "0.01"
        ],
        [
         "1",
         "valid",
         "5.0",
         "16.0",
         "22.0",
         "35.0",
         "40.0",
         "46.39999999999998",
         "63.95999999999996",
         "69.0",
         "1",
         "0.04"
        ],
        [
         "2",
         "test",
         "5.0",
         "15.0",
         "21.0",
         "25.0",
         "39.6",
         "40.8",
         "62.279999999999944",
         "69.0",
         "1",
         "0.04"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>tok_p0</th>\n",
       "      <th>tok_p25</th>\n",
       "      <th>tok_p50</th>\n",
       "      <th>tok_p75</th>\n",
       "      <th>tok_p90</th>\n",
       "      <th>tok_p95</th>\n",
       "      <th>tok_p99</th>\n",
       "      <th>tok_p100</th>\n",
       "      <th>tok_over_maxlen</th>\n",
       "      <th>tok_over_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.75</td>\n",
       "      <td>22.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>60.07</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valid</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46.4</td>\n",
       "      <td>63.96</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>40.8</td>\n",
       "      <td>62.28</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  tok_p0  tok_p25  tok_p50  tok_p75  tok_p90  tok_p95  tok_p99  \\\n",
       "0  train     5.0    14.75     22.0     33.0     44.0     48.0    60.07   \n",
       "1  valid     5.0    16.00     22.0     35.0     40.0     46.4    63.96   \n",
       "2   test     5.0    15.00     21.0     25.0     39.6     40.8    62.28   \n",
       "\n",
       "   tok_p100  tok_over_maxlen  tok_over_rate  \n",
       "0      72.0                2           0.01  \n",
       "1      69.0                1           0.04  \n",
       "2      69.0                1           0.04  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AUDIO QUALITY & ALIGNMENT (aggregates) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "('sr', 'min')",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "('sr', 'max')",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "('dur_sec', 'count')",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "('dur_sec', 'mean')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('dur_sec', 'median')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('dur_sec', 'max')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('clip_rate', 'mean')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('clip_rate', 'max')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('silence_rate', 'mean')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('silence_rate', 'max')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('len_diff', 'mean')",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "('len_diff', 'min')",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "('len_diff', 'max')",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "1eb7dc32-4010-469c-aa8e-c4bed1e880b9",
       "rows": [
        [
         "test",
         "16000",
         "16000",
         "25",
         "7.941257500000001",
         "7.0356875",
         "30.8825625",
         "2.049226057033725e-06",
         "2.833262501770789e-05",
         "0.02769260083829656",
         "0.18805451907131013",
         "0.0",
         "0",
         "0"
        ],
        [
         "train",
         "16000",
         "16000",
         "200",
         "7.865091562500001",
         "7.1579999999999995",
         "22.6626875",
         "1.2441884970554984e-06",
         "4.2471636909976054e-05",
         "0.027323553263578354",
         "0.4840876240480921",
         "0.0",
         "0",
         "0"
        ],
        [
         "valid",
         "16000",
         "16000",
         "25",
         "9.016475",
         "8.6610625",
         "18.4366875",
         "6.040562376357239e-07",
         "1.5101405940893098e-05",
         "0.03520611054398099",
         "0.23040133007650138",
         "0.0",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">sr</th>\n",
       "      <th colspan=\"4\" halign=\"left\">dur_sec</th>\n",
       "      <th colspan=\"2\" halign=\"left\">clip_rate</th>\n",
       "      <th colspan=\"2\" halign=\"left\">silence_rate</th>\n",
       "      <th colspan=\"3\" halign=\"left\">len_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>25</td>\n",
       "      <td>7.941258</td>\n",
       "      <td>7.035687</td>\n",
       "      <td>30.882562</td>\n",
       "      <td>2.049226e-06</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.027693</td>\n",
       "      <td>0.188055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>200</td>\n",
       "      <td>7.865092</td>\n",
       "      <td>7.158000</td>\n",
       "      <td>22.662688</td>\n",
       "      <td>1.244188e-06</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.027324</td>\n",
       "      <td>0.484088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>25</td>\n",
       "      <td>9.016475</td>\n",
       "      <td>8.661062</td>\n",
       "      <td>18.436688</td>\n",
       "      <td>6.040562e-07</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.035206</td>\n",
       "      <td>0.230401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sr        dur_sec                                    clip_rate  \\\n",
       "         min    max   count      mean    median        max          mean   \n",
       "split                                                                      \n",
       "test   16000  16000      25  7.941258  7.035687  30.882562  2.049226e-06   \n",
       "train  16000  16000     200  7.865092  7.158000  22.662688  1.244188e-06   \n",
       "valid  16000  16000      25  9.016475  8.661062  18.436688  6.040562e-07   \n",
       "\n",
       "                silence_rate           len_diff          \n",
       "            max         mean       max     mean min max  \n",
       "split                                                    \n",
       "test   0.000028     0.027693  0.188055      0.0   0   0  \n",
       "train  0.000042     0.027324  0.484088      0.0   0   0  \n",
       "valid  0.000015     0.035206  0.230401      0.0   0   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SPEAKER × EMOTION COVERAGE ===\n",
      "Rows: 250 | speakers: 250 | emotions: 5\n",
      "Cramér's V (speaker↔emotion): 1.000  (≈0: độc lập, →1: phụ thuộc mạnh)\n",
      "\n",
      "=== FLAGS / RECOMMENDATIONS ===\n",
      "- [Label balance] Gini = 0.80 > 0.40 (phân bố lệch).\n",
      "- [Bias] Cramér's V(speaker↔emotion)=1.00 cao. Nguy cơ model học speaker thay vì cảm xúc.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ### Dataset Audit for MER (VNEMOS JSONL)\n",
    "# Kiểm tra: cân bằng nhãn/speaker, độ dài audio & text, clipping/silence, căn chỉnh start/end,\n",
    "# rò rỉ giữa splits, và các chỉ số IR / Entropy / Gini / Cramér's V.\n",
    "\n",
    "# %%\n",
    "import os, json, math, re\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from IPython.display import display\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from configs.base import Config\n",
    "from loading.dataloader import VNEMOSDataset, _clean_text\n",
    "\n",
    "# ---------- helper metrics ----------\n",
    "def imbalance_ratio(counts: dict) -> float:\n",
    "    if not counts:\n",
    "        return float(\"nan\")\n",
    "    vals = np.array(list(counts.values()), dtype=float)\n",
    "    if vals.min() <= 0:\n",
    "        vals = vals[vals > 0]\n",
    "    if vals.size == 0:\n",
    "        return float(\"nan\")\n",
    "    return float(vals.max() / max(1.0, vals.min()))\n",
    "\n",
    "def norm_entropy(counts: dict) -> float:\n",
    "    vals = np.array(list(counts.values()), dtype=float)\n",
    "    if vals.sum() == 0 or len(vals) == 0:\n",
    "        return float(\"nan\")\n",
    "    p = vals / vals.sum()\n",
    "    H = -(p * np.log(p + 1e-12)).sum()\n",
    "    Hmax = math.log(len(vals)) if len(vals) > 0 else 1.0\n",
    "    return float(H / max(1e-12, Hmax))\n",
    "\n",
    "def gini_impurity(counts: dict) -> float:\n",
    "    vals = np.array(list(counts.values()), dtype=float)\n",
    "    if vals.sum() == 0:\n",
    "        return float(\"nan\")\n",
    "    p = vals / vals.sum()\n",
    "    return float(1.0 - (p**2).sum())\n",
    "\n",
    "def percentiles(arr, qs=(0, 25, 50, 75, 90, 95, 99, 100)):\n",
    "    if len(arr) == 0:\n",
    "        return {}\n",
    "    return {f\"p{q}\": float(np.percentile(arr, q)) for q in qs}\n",
    "\n",
    "def detect_clipping(x, thr=0.999):\n",
    "    if x.size == 0:\n",
    "        return 0.0\n",
    "    return float((np.abs(x) >= thr).mean())\n",
    "\n",
    "def silence_ratio(x, thr=1e-4):\n",
    "    if x.size == 0:\n",
    "        return 0.0\n",
    "    return float((np.abs(x) <= thr).mean())\n",
    "\n",
    "def cramers_v(conf_mat: np.ndarray) -> float:\n",
    "    if conf_mat.size == 0:\n",
    "        return 0.0\n",
    "    R, C = conf_mat.shape\n",
    "    total = conf_mat.sum()\n",
    "    if R < 2 or C < 2 or total == 0:\n",
    "        return 0.0\n",
    "    row_sums = conf_mat.sum(axis=1)\n",
    "    col_sums = conf_mat.sum(axis=0)\n",
    "    expected = np.outer(row_sums, col_sums) / max(1, total)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        term = (conf_mat - expected)**2 / np.where(expected==0, 1, expected)\n",
    "    chi2 = np.nansum(term)\n",
    "    k = min(R, C)\n",
    "    return float(np.sqrt(chi2 / (total * (k - 1) + 1e-12)))\n",
    "\n",
    "# ---------- config ----------\n",
    "cfg = Config(\n",
    "    data_root=\"../output\",\n",
    "    jsonl_dir=\"\",\n",
    "    sample_rate=16000,\n",
    "    max_audio_sec=None,       # kiểm đúng “không cắt cứng”\n",
    "    text_max_length=64,\n",
    ")\n",
    "\n",
    "# Tự động phát hiện các split có mặt\n",
    "splits = []\n",
    "for sp in [\"train\", \"valid\", \"test\"]:\n",
    "    p = (Path(cfg.data_root) / (cfg.jsonl_dir or \"\") / f\"{sp}.jsonl\").resolve()\n",
    "    if p.exists():\n",
    "        splits.append(sp)\n",
    "print(\"Found splits:\", splits)\n",
    "\n",
    "# ---------- load datasets ----------\n",
    "sets = {sp: VNEMOSDataset(cfg, sp) for sp in splits}\n",
    "tokenizer = AutoTokenizer.from_pretrained(getattr(cfg, \"text_encoder_ckpt\", \"vinai/phobert-base\"), use_fast=True)\n",
    "\n",
    "# ---------- collect rows (metadata) ----------\n",
    "rows = []\n",
    "for sp, ds in sets.items():\n",
    "    for it in ds.items:\n",
    "        rows.append({\n",
    "            \"split\": sp,\n",
    "            \"utterance_id\": it[\"utterance_id\"],\n",
    "            \"speaker_id\": it[\"speaker_id\"],\n",
    "            \"wav_path\": it[\"wav_path\"],\n",
    "            \"start\": float(it.get(\"start\", 0.0) or 0.0),\n",
    "            \"end\": float(it.get(\"end\", 0.0) or 0.0),\n",
    "            \"emotion\": it[\"emotion\"],\n",
    "            \"transcript\": _clean_text(it.get(\"transcript\", \"\")),\n",
    "        })\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Total rows:\", len(df))\n",
    "\n",
    "# ---------- existence (resolve) ----------\n",
    "missing = []\n",
    "abs_paths = []\n",
    "for sp, ds in sets.items():\n",
    "    for it in ds.items:\n",
    "        try:\n",
    "            wav_abs = str(ds._resolve_wav(it[\"wav_path\"]))\n",
    "            abs_paths.append((sp, wav_abs))\n",
    "        except Exception as e:\n",
    "            missing.append((sp, it[\"wav_path\"], str(e)))\n",
    "miss_df = pd.DataFrame(missing, columns=[\"split\",\"wav_path\",\"error\"])\n",
    "print(\"Missing/Unreadable files:\", len(miss_df))\n",
    "\n",
    "# ---------- duplicates (robust) ----------\n",
    "# Absolute path duplicates across all splits\n",
    "path_counts = Counter([p for _, p in abs_paths])\n",
    "dup_list = [{\"path\": p, \"count\": c} for p, c in path_counts.items() if c > 1]\n",
    "dup_df = pd.DataFrame(dup_list, columns=[\"path\",\"count\"])\n",
    "if not dup_df.empty:\n",
    "    dup_df = dup_df.sort_values(\"count\", ascending=False).reset_index(drop=True)\n",
    "print(\"Duplicate absolute wav paths (any split):\", 0 if dup_df.empty else len(dup_df))\n",
    "\n",
    "# Duplicate utterance_id across splits\n",
    "uid_counts = df.groupby([\"utterance_id\"]).size().sort_values(ascending=False)\n",
    "uid_dup_df = uid_counts[uid_counts > 1].rename(\"count\").reset_index()\n",
    "print(\"Duplicate utterance_id across splits:\", 0 if uid_dup_df.empty else len(uid_dup_df))\n",
    "\n",
    "# Duplicate JSONL wav_path across splits (relative path duplicates)\n",
    "rel_counts = df.groupby([\"wav_path\"]).size().sort_values(ascending=False)\n",
    "rel_dup_df = rel_counts[rel_counts > 1].rename(\"count\").reset_index()\n",
    "print(\"Duplicate JSONL wav_path across splits:\", 0 if rel_dup_df.empty else len(rel_dup_df))\n",
    "\n",
    "# ---------- leakage: speaker overlap ----------\n",
    "spk_by_split = {sp: set(df[df[\"split\"]==sp][\"speaker_id\"]) for sp in splits}\n",
    "overlap = {}\n",
    "for i, a in enumerate(splits):\n",
    "    for b in splits[i+1:]:\n",
    "        overlap[(a,b)] = len(spk_by_split[a].intersection(spk_by_split[b]))\n",
    "\n",
    "# ---------- label balance ----------\n",
    "label_counts = {sp: Counter(df[df[\"split\"]==sp][\"emotion\"]) for sp in splits}\n",
    "balance_table = []\n",
    "for sp in splits:\n",
    "    counts = dict(label_counts[sp])\n",
    "    row = {\n",
    "        \"split\": sp,\n",
    "        \"IR_max/min\": imbalance_ratio(counts),\n",
    "        \"H_norm\": norm_entropy(counts),\n",
    "        \"Gini\": gini_impurity(counts),\n",
    "        **{f\"cnt_{k}\": v for k, v in sorted(counts.items())},\n",
    "        \"total\": int(sum(counts.values())),\n",
    "    }\n",
    "    balance_table.append(row)\n",
    "balance_df = pd.DataFrame(balance_table).fillna(0)\n",
    "\n",
    "# ---------- token length & truncation ----------\n",
    "tok_stats = []\n",
    "for sp, ds in sets.items():\n",
    "    texts = df[df[\"split\"]==sp][\"transcript\"].tolist()\n",
    "    lens = []\n",
    "    over = 0\n",
    "    for txt in texts:\n",
    "        ids = tokenizer(txt, add_prefix_space=True)[\"input_ids\"]\n",
    "        L = len(ids); lens.append(L)\n",
    "        if L > cfg.text_max_length:\n",
    "            over += 1\n",
    "    arr = np.array(lens, dtype=int)\n",
    "    sts = percentiles(arr, qs=(0,25,50,75,90,95,99,100))\n",
    "    tok_stats.append({\n",
    "        \"split\": sp,\n",
    "        **{f\"tok_{k}\": v for k, v in sts.items()},\n",
    "        \"tok_over_maxlen\": int(over),\n",
    "        \"tok_over_rate\": float(over / max(1, len(arr))) if len(arr) else 0.0,\n",
    "    })\n",
    "tok_df = pd.DataFrame(tok_stats)\n",
    "\n",
    "# ---------- audio quality & alignment (read audio) ----------\n",
    "def expected_len_after_resample(wav_abs, start, end, target_sr):\n",
    "    info = sf.info(wav_abs)\n",
    "    orig_sr = info.samplerate\n",
    "    orig_frames = info.frames\n",
    "    if end and end > 0:\n",
    "        dur_s = max(0.0, end - start)\n",
    "    else:\n",
    "        dur_s = orig_frames / float(orig_sr)\n",
    "    return int(round(dur_s * target_sr))\n",
    "\n",
    "aq_rows = []\n",
    "for sp, ds in sets.items():\n",
    "    for it in ds.items:\n",
    "        try:\n",
    "            wav_abs = str(ds._resolve_wav(it[\"wav_path\"]))\n",
    "            data, sr = sf.read(wav_abs, always_2d=False)\n",
    "            if data.ndim == 2: \n",
    "                data = data.mean(axis=1)\n",
    "            # crop theo start/end\n",
    "            start = float(it.get(\"start\", 0.0) or 0.0)\n",
    "            end   = float(it.get(\"end\", 0.0) or 0.0)\n",
    "            if end and end > 0:\n",
    "                s = int(max(0.0, start) * sr)\n",
    "                e = min(int(end * sr), len(data))\n",
    "                data = data[s:e]\n",
    "            # metrics\n",
    "            clip = detect_clipping(data)\n",
    "            sil  = silence_ratio(data)\n",
    "            exp_len = expected_len_after_resample(wav_abs, start, end, cfg.sample_rate)\n",
    "            act_len = int(round(len(data) * (cfg.sample_rate / sr)))  # quy đổi về 16k\n",
    "            dur_sec = len(data) / float(sr) if sr > 0 else 0.0\n",
    "            aq_rows.append({\n",
    "                \"split\": sp,\n",
    "                \"wav_abs\": wav_abs,\n",
    "                \"sr\": sr,\n",
    "                \"len_samples\": int(len(data)),\n",
    "                \"dur_sec\": float(dur_sec),\n",
    "                \"clip_rate\": clip,\n",
    "                \"silence_rate\": sil,\n",
    "                \"len_expected_16k\": int(exp_len),\n",
    "                \"len_actual_16k\": int(act_len),\n",
    "                \"len_diff\": int(act_len - exp_len),\n",
    "            })\n",
    "        except Exception as e:\n",
    "            aq_rows.append({\"split\": sp, \"wav_abs\": it[\"wav_path\"], \"error\": str(e)})\n",
    "\n",
    "aq_df = pd.DataFrame(aq_rows)\n",
    "\n",
    "# ---------- speaker × emotion coverage & association ----------\n",
    "spk_em_rows = []\n",
    "for sp in splits:\n",
    "    sub = df[df[\"split\"]==sp]\n",
    "    if len(sub) == 0:\n",
    "        continue\n",
    "    grp = sub.groupby([\"speaker_id\",\"emotion\"]).size().reset_index(name=\"cnt\")\n",
    "    for spk, emo, cnt in grp.values:\n",
    "        spk_em_rows.append({\"split\": sp, \"speaker_id\": spk, \"emotion\": emo, \"count\": int(cnt)})\n",
    "spk_em_df = pd.DataFrame(spk_em_rows)\n",
    "\n",
    "pivot = df.pivot_table(index=\"speaker_id\", columns=\"emotion\", aggfunc=\"size\", fill_value=0)\n",
    "cramersV = cramers_v(pivot.values) if pivot.size > 0 else 0.0\n",
    "\n",
    "# ---------- SUMMARY ----------\n",
    "print(\"\\n=== EXISTENCE / DUPLICATION / LEAKAGE ===\")\n",
    "print(\"Missing files:\", len(miss_df))\n",
    "print(\"Duplicate absolute wav paths:\", 0 if dup_df.empty else len(dup_df))\n",
    "print(\"Duplicate utterance_id across splits:\", 0 if uid_dup_df.empty else len(uid_dup_df))\n",
    "print(\"Duplicate JSONL wav_path across splits:\", 0 if rel_dup_df.empty else len(rel_dup_df))\n",
    "print(\"Speaker overlap across splits:\", overlap)\n",
    "\n",
    "print(\"\\n=== LABEL BALANCE (per split) ===\")\n",
    "display(balance_df)\n",
    "\n",
    "print(\"\\n=== TOKEN LENGTH & TRUNCATION (per split) ===\")\n",
    "display(tok_df)\n",
    "\n",
    "print(\"\\n=== AUDIO QUALITY & ALIGNMENT (aggregates) ===\")\n",
    "if len(aq_df) > 0 and \"error\" not in aq_df.columns:\n",
    "    agg = aq_df.groupby(\"split\").agg({\n",
    "        \"sr\": [\"min\",\"max\"],\n",
    "        \"dur_sec\": [\"count\",\"mean\",\"median\",\"max\"],\n",
    "        \"clip_rate\": [\"mean\",\"max\"],\n",
    "        \"silence_rate\": [\"mean\",\"max\"],\n",
    "        \"len_diff\": [\"mean\",\"min\",\"max\"],\n",
    "    })\n",
    "    display(agg)\n",
    "else:\n",
    "    print(\"No audio inspected or errors present.\")\n",
    "    if \"error\" in aq_df.columns:\n",
    "        print(aq_df[[\"split\",\"wav_abs\",\"error\"]].head())\n",
    "\n",
    "print(\"\\n=== SPEAKER × EMOTION COVERAGE ===\")\n",
    "print(\"Rows:\", len(spk_em_df), \"| speakers:\", df['speaker_id'].nunique(), \"| emotions:\", df['emotion'].nunique())\n",
    "print(f\"Cramér's V (speaker↔emotion): {cramersV:.3f}  (≈0: độc lập, →1: phụ thuộc mạnh)\")\n",
    "\n",
    "# ---------- QUICK RULES / FLAGS ----------\n",
    "flags = []\n",
    "\n",
    "# A. Cân bằng nhãn (train)\n",
    "train_counts = label_counts.get(\"train\", Counter())\n",
    "if train_counts:\n",
    "    IR = imbalance_ratio(train_counts)\n",
    "    Hn = norm_entropy(train_counts)\n",
    "    Gi = gini_impurity(train_counts)\n",
    "    if IR > 3.0: flags.append(f\"[Label balance] Imbalance Ratio = {IR:.2f} > 3 (cân nhắc bổ sung/oversample/class-weight).\")\n",
    "    if Hn < 0.90: flags.append(f\"[Label balance] Entropy chuẩn hoá = {Hn:.2f} < 0.90 (phân bố lệch).\")\n",
    "    if Gi > 0.40: flags.append(f\"[Label balance] Gini = {Gi:.2f} > 0.40 (phân bố lệch).\")\n",
    "\n",
    "# B. Token truncation\n",
    "for sp in splits:\n",
    "    row = tok_df[tok_df[\"split\"]==sp]\n",
    "    if len(row):\n",
    "        rate = float(row[\"tok_over_rate\"].values[0])\n",
    "        if rate > 0.10:\n",
    "            flags.append(f\"[Text truncation] {sp}: {rate*100:.1f}% bị cắt > max_length={cfg.text_max_length}. Cân nhắc tăng text_max_length.\")\n",
    "\n",
    "# C. Audio quality\n",
    "if len(aq_df) and \"error\" not in aq_df.columns:\n",
    "    bysp = aq_df.groupby(\"split\").agg(clip_mean=(\"clip_rate\",\"mean\"), clip_max=(\"clip_rate\",\"max\"),\n",
    "                                      sil_mean=(\"silence_rate\",\"mean\"), sr_min=(\"sr\",\"min\"), sr_max=(\"sr\",\"max\"),\n",
    "                                      len_diff_min=(\"len_diff\",\"min\"), len_diff_max=(\"len_diff\",\"max\"))\n",
    "    for sp, r in bysp.iterrows():\n",
    "        if r[\"clip_max\"] > 0.01:\n",
    "            flags.append(f\"[Audio clipping] {sp}: clip_max={r['clip_max']:.3f} > 1%. Có thể normalize/gain staging.\")\n",
    "        if int(r[\"sr_min\"]) != 16000 or int(r[\"sr_max\"]) != 16000:\n",
    "            flags.append(f\"[Sample rate] {sp}: phát hiện sr khác 16k (min={int(r['sr_min'])}, max={int(r['sr_max'])}). Chuẩn hoá về 16k.\")\n",
    "        if abs(int(r[\"len_diff_min\"])) > 5 or abs(int(r[\"len_diff_max\"])) > 5:\n",
    "            flags.append(f\"[Alignment] {sp}: len_diff nên trong [-5,+5] mẫu @16k; thấy min={int(r['len_diff_min'])}, max={int(r['len_diff_max'])}.\")\n",
    "\n",
    "# D. Leakage\n",
    "for (a,b), n in overlap.items():\n",
    "    if n > 0:\n",
    "        flags.append(f\"[Leakage] Speaker trùng giữa {a} và {b}: {n} speaker. Nên tách disjoint.\")\n",
    "\n",
    "# E. Speaker bias\n",
    "if cramersV > 0.50:\n",
    "    flags.append(f\"[Bias] Cramér's V(speaker↔emotion)={cramersV:.2f} cao. Nguy cơ model học speaker thay vì cảm xúc.\")\n",
    "\n",
    "print(\"\\n=== FLAGS / RECOMMENDATIONS ===\")\n",
    "if flags:\n",
    "    for f in flags:\n",
    "        print(\"-\", f)\n",
    "else:\n",
    "    print(\"Không phát hiện vấn đề đáng lo theo các ngưỡng mặc định. ✅\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
