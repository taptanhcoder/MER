{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd3e26f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /mnt/d/MER/src\n",
      "Python: 3.12.3\n",
      "Torch: 2.7.1+cu126 | CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys, platform, torch, numpy as np\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7050e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from configs.base import Config\n",
    "\n",
    "\n",
    "import importlib\n",
    "import loading.dataloader as data_loader\n",
    "importlib.reload(data_loader)  \n",
    "\n",
    "from model.networks import MER   \n",
    "from model.losses import CrossEntropyLoss\n",
    "\n",
    "from training.trainer import TorchTrainer\n",
    "from training.callbacks import CheckpointsCallback\n",
    "from training.optimizers import split_param_groups, build_optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf26e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint dir: /mnt/d/MER/checkpoints/mer_vnemos\n",
      "base_dir: /mnt/d/MER/output\n",
      "audio_root (auto): /mnt/d/MER\n",
      "train.jsonl True\n",
      "valid.jsonl True\n",
      "test.jsonl True\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "\n",
    "cfg = Config(\n",
    "    name=\"MER_VNEMOS_PhoBERT_W2V2\",\n",
    "    checkpoint_dir=\"../checkpoints/mer_vnemos\",\n",
    "    num_epochs=2,\n",
    "    batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    optimizer_type=\"AdamW\",\n",
    "    save_best_val=True,\n",
    "    max_to_keep=2,\n",
    "    num_workers=2,\n",
    "\n",
    "\n",
    "    data_root=\"../output\",\n",
    "    jsonl_dir=\"\",\n",
    "\n",
    "\n",
    "    sample_rate=16000,\n",
    "    max_audio_sec=6.0,\n",
    "    text_max_length=64,\n",
    "\n",
    "    # Model\n",
    "    model_type=\"MemoCMT\",\n",
    "    text_encoder_type=\"phobert\",\n",
    "    text_encoder_ckpt=\"vinai/phobert-base\",\n",
    "    text_encoder_dim=768,\n",
    "    text_unfreeze=False,\n",
    "\n",
    "    audio_encoder_type=\"wav2vec2_xlsr\",\n",
    "    audio_encoder_ckpt=\"facebook/wav2vec2-large-xlsr-53\",\n",
    "    audio_encoder_dim=1024,\n",
    "    audio_unfreeze=False,\n",
    "\n",
    "    fusion_dim=768,\n",
    "    fusion_head_output_type=\"mean\",\n",
    "    linear_layer_output=[128],\n",
    "\n",
    "    use_amp=True,\n",
    "    max_grad_norm=1.0,\n",
    ")\n",
    "\n",
    "FRACTION = 0.1\n",
    "SEED = 42\n",
    "STRATIFIED = True\n",
    "\n",
    "print(\"Checkpoint dir:\", Path(cfg.checkpoint_dir).resolve())\n",
    "base_dir = (Path(cfg.data_root) / (cfg.jsonl_dir or \"\")).resolve()\n",
    "print(\"base_dir:\", base_dir)\n",
    "print(\"audio_root (auto):\", Path(getattr(cfg, \"audio_root\", base_dir.parent)).resolve())\n",
    "for fn in [\"train.jsonl\",\"valid.jsonl\",\"test.jsonl\"]:\n",
    "    print(fn, (base_dir/fn).exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6770cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 5 ['angry', 'fear', 'happiness', 'neutral', 'sadness']\n",
      "Train batches: 3 | Eval batches: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import Subset, RandomSampler\n",
    "\n",
    "def _subset_indices_random(n, fraction, seed=42):\n",
    "    k = max(1, int(round(n * fraction)))\n",
    "    rng = np.random.RandomState(seed)\n",
    "    idx = np.arange(n)\n",
    "    rng.shuffle(idx)\n",
    "    return idx[:k].tolist()\n",
    "\n",
    "def _subset_indices_stratified_vnemos(ds, fraction, seed=42):\n",
    "\n",
    "    label2inds = {}\n",
    "    for i, ex in enumerate(ds.items):\n",
    "        y = ds.label2id[ex[\"emotion\"]]\n",
    "        label2inds.setdefault(y, []).append(i)\n",
    "    rng = np.random.RandomState(seed)\n",
    "    out = []\n",
    "    for y, inds in label2inds.items():\n",
    "        k = max(1, int(round(len(inds) * fraction)))\n",
    "        rng.shuffle(inds)\n",
    "        out.extend(inds[:k])\n",
    "    rng.shuffle(out)\n",
    "    return out\n",
    "\n",
    "def _subset_loader(loader, fraction=1.0, seed=42, stratified=False):\n",
    "    if fraction >= 0.999:\n",
    "        return loader\n",
    "    ds = loader.dataset\n",
    "    if stratified and hasattr(ds, \"items\") and hasattr(ds, \"label2id\"):\n",
    "        indices = _subset_indices_stratified_vnemos(ds, fraction, seed)\n",
    "    else:\n",
    "        indices = _subset_indices_random(len(ds), fraction, seed)\n",
    "    subset = Subset(ds, indices)\n",
    "\n",
    "    shuffle = isinstance(loader.sampler, RandomSampler)\n",
    "    return type(loader)(\n",
    "        subset,\n",
    "        batch_size=loader.batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=loader.num_workers,\n",
    "        collate_fn=loader.collate_fn,\n",
    "        pin_memory=loader.pin_memory,\n",
    "        drop_last=loader.drop_last,\n",
    "    )\n",
    "\n",
    "\n",
    "train_loader, eval_loader = data_loader.build_train_test_dataset(cfg)\n",
    "\n",
    "\n",
    "train_ds = train_loader.dataset\n",
    "if hasattr(train_ds, \"label2id\"):\n",
    "    cfg.num_classes = len(train_ds.label2id)\n",
    "    id2label = [k for k, v in sorted(train_ds.label2id.items(), key=lambda x: x[1])]\n",
    "else:\n",
    "    cfg.num_classes = 4\n",
    "    id2label = list(range(cfg.num_classes))\n",
    "\n",
    "\n",
    "train_loader = _subset_loader(train_loader, fraction=FRACTION, seed=SEED, stratified=STRATIFIED)\n",
    "if eval_loader is not None:\n",
    "    eval_loader = _subset_loader(eval_loader, fraction=FRACTION, seed=SEED, stratified=STRATIFIED)\n",
    "\n",
    "print(\"Classes:\", cfg.num_classes, id2label)\n",
    "print(f\"Train batches: {len(train_loader)} | Eval batches: {len(eval_loader) if eval_loader else 0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d58f9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer ready. Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75968/1288909379.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import BatchEncoding\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "network = MER(cfg, device=device)\n",
    "criterion = CrossEntropyLoss(cfg)\n",
    "\n",
    "class MERTrainer(TorchTrainer):\n",
    "    def __init__(self, cfg, network, criterion, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cfg = cfg\n",
    "        self.network = network\n",
    "        self.criterion = criterion\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.network.to(self.device)\n",
    "        self.use_amp = bool(getattr(cfg, \"use_amp\", torch.cuda.is_available()))\n",
    "        self.max_grad_norm = float(getattr(cfg, \"max_grad_norm\", 0.0))\n",
    "        self.scaler = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
    "\n",
    "    def _to_device_text(self, x):\n",
    "\n",
    "        if isinstance(x, BatchEncoding):\n",
    "            x = x.to(self.device)\n",
    "            return {k: v for k, v in x.items()}\n",
    "        if isinstance(x, dict):\n",
    "            return {k: v.to(self.device) for k, v in x.items()}\n",
    "\n",
    "        return x.to(self.device)\n",
    "\n",
    "    def _standardize_batch(self, batch):\n",
    "        \"\"\"\n",
    "        Chuẩn hoá về (tok_dict, audio_tensor, labels_tensor).\n",
    "        Hỗ trợ:\n",
    "          - (tok, audio, labels)\n",
    "          - ((tok, audio, labels), meta)\n",
    "          - {\"text\": tok, \"audio\": audio, \"label\": labels}\n",
    "          - (tok_dict, (audio, labels))\n",
    "        \"\"\"\n",
    "        if isinstance(batch, (tuple, list)) and len(batch) == 2:\n",
    "            a, b = batch\n",
    "            if isinstance(a, (tuple, list)) and len(a) == 3:\n",
    "                return a\n",
    "            if isinstance(b, (tuple, list)) and len(b) == 3:\n",
    "                return b\n",
    "            if isinstance(a, (dict, BatchEncoding)) and isinstance(b, (tuple, list)) and len(b) == 2:\n",
    "                tok = a\n",
    "                audio, labels = b\n",
    "                return tok, audio, labels\n",
    "\n",
    "        if isinstance(batch, (tuple, list)) and len(batch) == 3:\n",
    "            return batch\n",
    "\n",
    "        if isinstance(batch, dict):\n",
    "            tok = batch.get(\"text\"); audio = batch.get(\"audio\"); labels = batch.get(\"label\")\n",
    "            if tok is not None and audio is not None and labels is not None:\n",
    "                return tok, audio, labels\n",
    "\n",
    "        raise ValueError(f\"Batch structure không hỗ trợ: preview={str(batch)[:200]}\")\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        self.network.train()\n",
    "        self.optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        input_text, input_audio, labels = self._standardize_batch(batch)\n",
    "        input_audio = input_audio.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        input_text = self._to_device_text(input_text)\n",
    "\n",
    "        if self.use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = self.network(input_text, input_audio)\n",
    "                logits = out[0] if isinstance(out, (tuple, list)) else out\n",
    "                loss = self.criterion(out, labels) if isinstance(out, (tuple, list)) else self.criterion(logits, labels)\n",
    "            self.scaler.scale(loss).backward()\n",
    "            if self.max_grad_norm and self.max_grad_norm > 0:\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(self.network.parameters(), self.max_grad_norm)\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "        else:\n",
    "            out = self.network(input_text, input_audio)\n",
    "            logits = out[0] if isinstance(out, (tuple, list)) else out\n",
    "            loss = self.criterion(out, labels) if isinstance(out, (tuple, list)) else self.criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            if self.max_grad_norm and self.max_grad_norm > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(self.network.parameters(), self.max_grad_norm)\n",
    "            self.optimizer.step()\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == labels).float().mean()\n",
    "        return {\"loss\": float(loss.detach().cpu()), \"acc\": float(acc.detach().cpu())}\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        self.network.eval()\n",
    "        input_text, input_audio, labels = self._standardize_batch(batch)\n",
    "        input_audio = input_audio.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        input_text = self._to_device_text(input_text)\n",
    "        with torch.no_grad():\n",
    "            out = self.network(input_text, input_audio)\n",
    "            logits = out[0] if isinstance(out, (tuple, list)) else out\n",
    "            loss = self.criterion(out, labels) if isinstance(out, (tuple, list)) else self.criterion(logits, labels)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            acc = (preds == labels).float().mean()\n",
    "        return {\"val_loss\": float(loss.detach().cpu()), \"val_acc\": float(acc.detach().cpu())}\n",
    "\n",
    "trainer = MERTrainer(cfg, network, criterion, log_dir=\"logs\")\n",
    "print(\"Trainer ready. Device:\", trainer.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a879bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param groups: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "param_groups = split_param_groups(trainer, lr_enc=cfg.learning_rate * 0.25,\n",
    "                                  lr_head=cfg.learning_rate, weight_decay=0.01)\n",
    "optimizer = build_optimizer(\"adamw\", param_groups, lr=cfg.learning_rate, weight_decay=0.01)\n",
    "\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=max(1, cfg.num_epochs))\n",
    "trainer.compile(optimizer=optimizer, scheduler=scheduler, lr=cfg.learning_rate, param_groups=None)\n",
    "print(\"Param groups:\", len(optimizer.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea0c8019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-09 13:52:14,975 - root - WARNING - save_best_val=True → cần truyền validation loader vào trainer.fit(). Best theo metric 'val_loss' (min).\n",
      "Epoch 1/2\n",
      "2025-08-09 13:52:15,367 - Training - INFO - Epoch 1/2\n",
      "Epoch 1:   0%|          | 0/3 [00:00<?, ?it/s]Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "/tmp/ipykernel_75968/1288909379.py:69: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/mnt/d/MER/tf/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Epoch 1:  33%|###3      | 1/3 [00:22<00:45, 22.66s/it, loss: 1.6635 | acc: 0.1250]/tmp/ipykernel_75968/1288909379.py:69: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/mnt/d/MER/tf/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Epoch 1: 100%|##########| 3/3 [00:29<00:00,  9.83s/it, loss: 1.7312 | acc: 0.0000]\n",
      "Epoch 1 - loss: 1.6839\n",
      "2025-08-09 13:52:44,853 - Training - INFO - Epoch 1 - loss: 1.6839\n",
      "Epoch 1 - acc: 0.0833\n",
      "2025-08-09 13:52:45,063 - Training - INFO - Epoch 1 - acc: 0.0833\n",
      "Performing validation...\n",
      "2025-08-09 13:52:45,297 - Training - INFO - Performing validation...\n",
      "Valid:   0%|          | 0/1 [00:00<?, ?it/s]Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Valid: 100%|##########| 1/1 [00:02<00:00,  2.51s/it]\n",
      "Validation: val_loss: 1.6207 val_acc: 0.2000\n",
      "2025-08-09 13:52:47,815 - Training - INFO - Validation: val_loss: 1.6207 val_acc: 0.2000\n",
      "Improved val_loss from inf to 1.620691. Saving best...\n",
      "2025-08-09 13:52:48,351 - Training - INFO - Improved val_loss from inf to 1.620691. Saving best...\n",
      "Epoch 2/2\n",
      "2025-08-09 13:52:59,609 - Training - INFO - Epoch 2/2\n",
      "Epoch 2:   0%|          | 0/3 [00:00<?, ?it/s]Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Epoch 2: 100%|##########| 3/3 [00:11<00:00,  3.67s/it, loss: 1.5779 | acc: 0.2500]\n",
      "Epoch 2 - loss: 1.6099\n",
      "2025-08-09 13:53:10,627 - Training - INFO - Epoch 2 - loss: 1.6099\n",
      "Epoch 2 - acc: 0.2083\n",
      "2025-08-09 13:53:10,891 - Training - INFO - Epoch 2 - acc: 0.2083\n",
      "Performing validation...\n",
      "2025-08-09 13:53:11,159 - Training - INFO - Performing validation...\n",
      "Valid:   0%|          | 0/1 [00:00<?, ?it/s]Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Valid: 100%|##########| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Validation: val_loss: 1.6052 val_acc: 0.2000\n",
      "2025-08-09 13:53:12,940 - Training - INFO - Validation: val_loss: 1.6052 val_acc: 0.2000\n",
      "Improved val_loss from 1.620691 to 1.605211. Saving best...\n",
      "2025-08-09 13:53:13,445 - Training - INFO - Improved val_loss from 1.620691 to 1.605211. Saving best...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint: ../checkpoints/mer_vnemos/best_val_loss/checkpoint_0.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ckpt_cb = CheckpointsCallback(cfg.checkpoint_dir, save_freq=200, max_to_keep=2,\n",
    "                              save_best_val=True, monitor=\"val_loss\", mode=\"min\")\n",
    "trainer.fit(train_loader, epochs=cfg.num_epochs, eval_data=eval_loader, callbacks=[ckpt_cb])\n",
    "print(\"Best checkpoint:\", getattr(ckpt_cb, \"best_path\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea891ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n",
      "Keyword arguments {'add_prefix_space': True} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Acc: 0.2000\n",
      "Per-class Acc:\n",
      "  0 (angry): 1.0000\n",
      "  1 (fear): 0.0000\n",
      "  2 (happiness): 0.0000\n",
      "  3 (neutral): 0.0000\n",
      "  4 (sadness): 0.0000\n",
      "Confusion Matrix:\n",
      " [[1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry     0.5000    1.0000    0.6667         1\n",
      "        fear     0.0000    0.0000    0.0000         1\n",
      "   happiness     0.0000    0.0000    0.0000         1\n",
      "     neutral     0.0000    0.0000    0.0000         1\n",
      "     sadness     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.2000         5\n",
      "   macro avg     0.1000    0.2000    0.1333         5\n",
      "weighted avg     0.1000    0.2000    0.1333         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/MER/tf/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/mnt/d/MER/tf/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/mnt/d/MER/tf/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# %%  (EVALUATION — sửa để tái dùng chuẩn hoá batch của trainer)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def collect_preds(trainer, loader):\n",
    "    all_preds, all_labels = [], []\n",
    "    trainer.network.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            # DÙ batch ở dạng gì, chuẩn hoá về (tok_dict, audio, labels)\n",
    "            input_text, input_audio, labels = trainer._standardize_batch(batch)\n",
    "            input_audio = input_audio.to(trainer.device)\n",
    "            labels = labels.to(trainer.device)\n",
    "            input_text = trainer._to_device_text(input_text)\n",
    "\n",
    "            out = trainer.network(input_text, input_audio)\n",
    "            logits = out[0] if isinstance(out, (tuple, list)) else out\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    return torch.cat(all_preds), torch.cat(all_labels)\n",
    "\n",
    "if eval_loader is not None:\n",
    "    preds, labels = collect_preds(trainer, eval_loader)\n",
    "    num_classes = cfg.num_classes\n",
    "\n",
    "    # Confusion matrix + metrics\n",
    "    cm = torch.zeros((num_classes, num_classes), dtype=torch.int32)\n",
    "    for t, p in zip(labels, preds):\n",
    "        cm[t.long(), p.long()] += 1\n",
    "\n",
    "    per_class_acc = (cm.diag().float() / cm.sum(dim=1).clamp(min=1).float()).numpy()\n",
    "    overall_acc = (preds == labels).float().mean().item()\n",
    "\n",
    "    print(\"Overall Acc: %.4f\" % overall_acc)\n",
    "    print(\"Per-class Acc:\")\n",
    "    for i, acc in enumerate(per_class_acc):\n",
    "        name = str(i)\n",
    "        try:\n",
    "            name = id2label[i]\n",
    "        except Exception:\n",
    "            pass\n",
    "        print(f\"  {i} ({name}): {acc:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", cm.numpy())\n",
    "\n",
    "    # Classification report (nếu sklearn có sẵn)\n",
    "    try:\n",
    "        from sklearn.metrics import classification_report\n",
    "        target_names = [str(i) for i in range(num_classes)]\n",
    "        try:\n",
    "            target_names = [id2label[i] for i in range(num_classes)]\n",
    "        except Exception:\n",
    "            pass\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(labels.numpy(), preds.numpy(), target_names=target_names, digits=4))\n",
    "    except Exception:\n",
    "        pass\n",
    "else:\n",
    "    print(\"No eval_loader available.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
